#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de EvaluaciÃ³n: v1.5 vs v2.0
Compara rendimiento y calidad entre versiones
"""

import sys
import time
import json
from pathlib import Path
from typing import List, Dict
import numpy as np

# Importar ambas versiones
sys.path.insert(0, 'uploads')
from ultralite_qoyllur_v15 import UltraLiteQoyllurV15
from graphrag_v2 import GraphRAG_v2


class Evaluador:
    """Evaluador de calidad y rendimiento"""
    
    def __init__(self, ttl_path: str):
        print("=" * 80)
        print("ğŸ”¬ EVALUADOR: v1.5 vs v2.0")
        print("=" * 80)
        
        self.ttl_path = ttl_path
        
        # Cargar ambas versiones
        print("\nğŸ“¦ Cargando v1.5...")
        start = time.time()
        self.v15 = UltraLiteQoyllurV15(ttl_path)
        t15 = time.time() - start
        print(f"   âœ… v1.5 cargada en {t15:.2f}s")
        
        print("\nğŸ“¦ Cargando v2.0...")
        start = time.time()
        self.v20 = GraphRAG_v2(ttl_path)
        t20 = time.time() - start
        print(f"   âœ… v2.0 cargada en {t20:.2f}s")
        
        print(f"\nâ±ï¸  Tiempo de carga: v2.0 es {t20/t15:.1f}x mÃ¡s lento (esperado por embeddings)")
    
    def evaluar_latencia(self, queries: List[str]) -> Dict:
        """Mide latencia de respuesta"""
        print("\n" + "=" * 80)
        print("â±ï¸  EVALUACIÃ“N DE LATENCIA")
        print("=" * 80)
        
        resultados = {
            'v15': [],
            'v20_semantico': [],
            'v20_lexico': [],
            'v20_hibrido': []
        }
        
        for query in queries:
            print(f"\nğŸ“ Query: {query}")
            
            # v1.5
            start = time.time()
            _ = self.v15.responder(query)
            t = time.time() - start
            resultados['v15'].append(t)
            print(f"   v1.5: {t*1000:.1f}ms")
            
            # v2.0 semÃ¡ntico
            start = time.time()
            _ = self.v20.responder(query, modo="semantico", verbose=False)
            t = time.time() - start
            resultados['v20_semantico'].append(t)
            print(f"   v2.0 (semÃ¡ntico): {t*1000:.1f}ms")
            
            # v2.0 lÃ©xico
            start = time.time()
            _ = self.v20.responder(query, modo="lexico", verbose=False)
            t = time.time() - start
            resultados['v20_lexico'].append(t)
            print(f"   v2.0 (lÃ©xico): {t*1000:.1f}ms")
            
            # v2.0 hÃ­brido
            start = time.time()
            _ = self.v20.responder(query, modo="hibrido", verbose=False)
            t = time.time() - start
            resultados['v20_hibrido'].append(t)
            print(f"   v2.0 (hÃ­brido): {t*1000:.1f}ms")
        
        # Calcular estadÃ­sticas
        print("\n" + "=" * 80)
        print("ğŸ“Š RESUMEN DE LATENCIA")
        print("=" * 80)
        
        for version, tiempos in resultados.items():
            media = np.mean(tiempos) * 1000
            std = np.std(tiempos) * 1000
            minimo = np.min(tiempos) * 1000
            maximo = np.max(tiempos) * 1000
            
            print(f"\n{version}:")
            print(f"   Media: {media:.1f}ms (Â±{std:.1f}ms)")
            print(f"   Min/Max: {minimo:.1f}ms / {maximo:.1f}ms")
        
        return resultados
    
    def evaluar_calidad(self, test_cases: List[Dict]) -> Dict:
        """
        EvalÃºa calidad de respuestas
        
        test_cases: Lista de {
            'query': str,
            'tipo': str (donde/cuando/quien/que),
            'entidad_esperada': str,
            'keywords_esperados': List[str]
        }
        """
        print("\n" + "=" * 80)
        print("ğŸ¯ EVALUACIÃ“N DE CALIDAD")
        print("=" * 80)
        
        resultados = {
            'v15': {'aciertos': 0, 'total': 0},
            'v20_semantico': {'aciertos': 0, 'total': 0},
            'v20_hibrido': {'aciertos': 0, 'total': 0}
        }
        
        for i, test in enumerate(test_cases, 1):
            query = test['query']
            entidad_esperada = test['entidad_esperada']
            keywords = test.get('keywords_esperados', [])
            
            print(f"\n{'='*80}")
            print(f"Test {i}/{len(test_cases)}: {query}")
            print(f"Tipo: {test['tipo']} | Entidad esperada: {entidad_esperada}")
            print(f"{'='*80}")
            
            # v1.5
            print("\nğŸ”µ v1.5:")
            resp15 = self.v15.responder(query)
            print(f"   {resp15[:200]}...")
            
            # Verificar si encontrÃ³ la entidad correcta
            v15_correcto = entidad_esperada.lower() in resp15.lower()
            if v15_correcto:
                resultados['v15']['aciertos'] += 1
                print("   âœ… Entidad correcta encontrada")
            else:
                print("   âŒ Entidad esperada no encontrada")
            resultados['v15']['total'] += 1
            
            # v2.0 semÃ¡ntico
            print("\nğŸŸ¢ v2.0 (semÃ¡ntico):")
            resp20_sem = self.v20.responder(query, modo="semantico", verbose=False)
            print(f"   {resp20_sem[:200]}...")
            
            v20_sem_correcto = entidad_esperada.lower() in resp20_sem.lower()
            if v20_sem_correcto:
                resultados['v20_semantico']['aciertos'] += 1
                print("   âœ… Entidad correcta encontrada")
            else:
                print("   âŒ Entidad esperada no encontrada")
            resultados['v20_semantico']['total'] += 1
            
            # v2.0 hÃ­brido
            print("\nğŸŸ£ v2.0 (hÃ­brido):")
            resp20_hyb = self.v20.responder(query, modo="hibrido", verbose=False)
            print(f"   {resp20_hyb[:200]}...")
            
            v20_hyb_correcto = entidad_esperada.lower() in resp20_hyb.lower()
            if v20_hyb_correcto:
                resultados['v20_hibrido']['aciertos'] += 1
                print("   âœ… Entidad correcta encontrada")
            else:
                print("   âŒ Entidad esperada no encontrada")
            resultados['v20_hibrido']['total'] += 1
        
        # Resumen
        print("\n" + "=" * 80)
        print("ğŸ“Š RESUMEN DE CALIDAD")
        print("=" * 80)
        
        for version, stats in resultados.items():
            if stats['total'] > 0:
                precision = (stats['aciertos'] / stats['total']) * 100
                print(f"\n{version}:")
                print(f"   Aciertos: {stats['aciertos']}/{stats['total']}")
                print(f"   PrecisiÃ³n: {precision:.1f}%")
        
        return resultados
    
    def test_sinonimos(self):
        """Prueba capacidad de entender sinÃ³nimos (ventaja de v2.0)"""
        print("\n" + "=" * 80)
        print("ğŸ”¤ TEST DE SINÃ“NIMOS Y PARÃFRASIS")
        print("=" * 80)
        print("v2.0 deberÃ­a tener ventaja aquÃ­ gracias a embeddings\n")
        
        # Pares de queries equivalentes
        pares = [
            ("Â¿QuÃ© hacen los ukukus?", "Â¿CuÃ¡l es la funciÃ³n de los ukumaris?"),
            ("Â¿DÃ³nde estÃ¡ el santuario?", "Â¿CuÃ¡l es la ubicaciÃ³n del lugar sagrado?"),
            ("Â¿CuÃ¡ndo es la peregrinaciÃ³n?", "Â¿En quÃ© fecha ocurre el viaje?"),
        ]
        
        for original, parafrasis in pares:
            print(f"\nğŸ“ Original: {original}")
            print(f"ğŸ“ ParÃ¡frasis: {parafrasis}")
            
            # Buscar con v2.0
            results_orig = self.v20.buscar_semantico(original, top_k=3)
            results_para = self.v20.buscar_semantico(parafrasis, top_k=3)
            
            print("\n   Top-3 resultados:")
            print("   Original:")
            for ent_id, score in results_orig:
                ent = self.v20.entidades[ent_id]
                nombre = ent['labels'][0] if ent['labels'] else ent_id
                print(f"      â€¢ {nombre} ({score:.3f})")
            
            print("   ParÃ¡frasis:")
            for ent_id, score in results_para:
                ent = self.v20.entidades[ent_id]
                nombre = ent['labels'][0] if ent['labels'] else ent_id
                print(f"      â€¢ {nombre} ({score:.3f})")
            
            # Calcular similitud entre resultados
            top1_orig = results_orig[0][0] if results_orig else None
            top1_para = results_para[0][0] if results_para else None
            
            if top1_orig == top1_para:
                print(f"   âœ… Mismo top-1 resultado (consistencia alta)")
            else:
                print(f"   âš ï¸  Diferentes top-1 (puede variar segÃºn parÃ¡frasis)")


def main():
    """Ejecuta suite completa de evaluaciÃ³n"""
    
    # ConfiguraciÃ³n - usar ruta relativa o pedir al usuario
    ttl_path = "qoyllurity.ttl"
    
    if not Path(ttl_path).exists():
        # Intentar rutas alternativas comunes
        rutas_alternativas = [
            "/mnt/user-data/uploads/qoyllurity.ttl",
            "../qoyllurity.ttl",
            "data/qoyllurity.ttl"
        ]
        
        for ruta in rutas_alternativas:
            if Path(ruta).exists():
                ttl_path = ruta
                break
        else:
            print(f"âŒ No se encontrÃ³: {ttl_path}")
            ttl_path = input("Ingresa la ruta al archivo TTL: ").strip()
            if not Path(ttl_path).exists():
                print("âŒ Archivo no encontrado. Abortando.")
                return
    
    # Crear evaluador
    evaluador = Evaluador(ttl_path)
    
    # 1. Test de latencia
    queries_latencia = [
        "Â¿QuÃ© es Qoyllur Rit'i?",
        "Â¿DÃ³nde estÃ¡ el santuario?",
        "Â¿QuÃ© hacen los ukukus?",
        "Â¿CuÃ¡ndo es la bajada del glaciar?",
        "Â¿QuiÃ©n realiza la lomada?",
    ]
    
    latencia_results = evaluador.evaluar_latencia(queries_latencia)
    
    # 2. Test de calidad
    test_cases = [
        {
            'query': 'Â¿QuÃ© es Qoyllur Rit\'i?',
            'tipo': 'que',
            'entidad_esperada': 'Festividad',
            'keywords_esperados': ['peregrinaciÃ³n', 'andina', 'Sinakara']
        },
        {
            'query': 'Â¿DÃ³nde estÃ¡ el glaciar Colque Punku?',
            'tipo': 'donde',
            'entidad_esperada': 'Colque Punku',
            'keywords_esperados': ['glaciar', '5200']
        },
        {
            'query': 'Â¿QuiÃ©n realiza la lomada?',
            'tipo': 'quien',
            'entidad_esperada': 'Nacion',
            'keywords_esperados': ['Paucartambo', 'Ukumaris']
        },
        {
            'query': 'Â¿QuÃ© eventos hay el dÃ­a 2?',
            'tipo': 'que_eventos',
            'entidad_esperada': 'Domingo',
            'keywords_esperados': ['misa', 'partida', 'viaje']
        },
    ]
    
    calidad_results = evaluador.evaluar_calidad(test_cases)
    
    # 3. Test de sinÃ³nimos
    evaluador.test_sinonimos()
    
    # 4. Guardar resultados
    resultados_finales = {
        'latencia': {k: [float(x) for x in v] for k, v in latencia_results.items()},
        'calidad': calidad_results,
        'timestamp': time.time()
    }
    
    # Usar ruta relativa que funciona en cualquier OS
    output_file = "evaluacion_v15_vs_v20.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(resultados_finales, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Resultados guardados en: {output_file}")
    
    # 5. ConclusiÃ³n
    print("\n" + "=" * 80)
    print("ğŸ¯ CONCLUSIONES")
    print("=" * 80)
    print("""
v1.5 (UltraLite):
  âœ… MÃ¡s rÃ¡pido (~50-100ms)
  âœ… Menor uso de RAM (~100MB)
  âŒ BÃºsqueda solo lÃ©xica
  âŒ No entiende sinÃ³nimos

v2.0 (Embeddings):
  âœ… BÃºsqueda semÃ¡ntica
  âœ… Entiende sinÃ³nimos y parÃ¡frasis
  âœ… Mejor ranking de resultados
  âŒ MÃ¡s lento (~200-300ms)
  âŒ MÃ¡s RAM (~500MB)

RECOMENDACIÃ“N:
  â†’ Usar v2.0 para producciÃ³n si 200-300ms es aceptable
  â†’ Mantener v1.5 si necesitas <100ms de latencia
  â†’ v2.0 modo 'hÃ­brido' ofrece mejor balance
""")
    
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
